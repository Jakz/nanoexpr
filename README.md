# NanoExpr

A small lexer/parser/compiler for expressions (and something more) based on C++17 features.

This has been written for hobby and to have something lightweight to embed in other applications, since a full Flex/Bison stack is not always needed (and adds complexity to build phase).

The phases are
* lexing into tokens
* parsing tokens into an abstract syntax tree
* compile the tree recursively by producing a final lambda

So there's no VM which actually executes the code, but C++14 named value bindings to lambda come to rescue and allows nesting lambdas, for example:

`LiteralValue(4.0)` is compiled as `[](vm::Environment* env) { return Value(4.0); }`, while a standard function call like `3.0 + 4.0` is compiled by invoking the *lhs* and *rhs* lambdas and then combine the result, eg:

    std::function<Value()> BinaryFunction::compile()
    {
      auto function = [] (const Value v1, const Value v2) { return v1 + v2; }
      auto left = left->compile();
      auto right = right->compile();
      return [left = left, right = right, function = function] { return function(left(), right()); }
    }
    
Which is rather simple to implement and has the advantage of being easily foldable to another value if we now that what this calculates is constant.

The language supports `int`, `float` and `bool` types for now, many std functions are being added which can be optionally be excluded.

# Components

## Lexer

`lex::Lexer` class implements the _lexer_, its purpose is to turn a `std:string` into a `std::vector<Token>` which can be subsequently turned into an abstract syntax tree by the parser.

__Basic usage__:

	lex::Lexer lexer;
	auto result = lexer.parse("input");

	if (result)
	  auto tokens = result.tokens;
	else
	  std::cout << "lexer error: " << result.message << std::endl;

## Parser

The _parser_ turns a sequence of `Token` object in a tree which represent the structure of the code being parsed. This structure matches how each piece of the language is assembled into statements or expressions, discarding all the tokens which have no semantics (eg. whitespace, delimiters and such). It turns a `std::vector<Token>` into an `ast::Expression*` which is the root of the tree.

__Basic usage__:

    std::vector<Token> tokens = ...;

    parser::Parser parser;
    auto result = parser.parse(tokens);

    if (result)
      auto root = result.ast;
    else
      std::cout << "parser error: " << result.message << std::endl;

 ## Compiler

There's no real _compiler_ because the executable code is generated by visiting the syntax tree directly with a recursive function. This means that there is no `Compiler` object anywhere. To turn the tree into executable code you just call compile function on root an pass the `Environment` to the function (discussed below).

__Basic usage__:
	
	auto ast = parser::Parser().parse(lex::Lexer().parse("1+2"));

	vm::Environment env;
	const vm::lambda_t& lambda = ast->compile(&env);
	assert(lambda().as<integral_t>() == 3);